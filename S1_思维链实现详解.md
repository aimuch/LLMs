# s1项目思维链（Chain of Thought）实现详解

## 目录
1. [项目概述](#1-项目概述)
2. [思维链数据准备](#2-思维链数据准备)
3. [训练机制](#3-训练机制)
4. [推理机制](#4-推理机制)
5. [Prompt设计](#5-prompt设计)
6. [代码示例](#6-代码示例)
7. [关键创新点](#7-关键创新点)

---

## 1. 项目概述

s1是一个通过简单的测试时扩展（test-time scaling）实现强大推理能力的项目。核心特点：
- 仅使用1000个高质量训练样本（s1K数据集）
- 通过思维链技术提升模型推理能力
- 实现了灵活的思维链控制机制

### 关键组件
- **基础模型**: Qwen2.5-32B-Instruct
- **特殊标记**: 
  - `<|im_start|>think`: 思维链开始标记
  - `<|im_start|>answer`: 答案开始标记
  - `<|im_end|>`: 结束标记

---

## 2. 思维链数据准备

### 2.1 数据收集流程

#### 第一步：问题收集 (`data/collect_data.py`)
```python
# 从多个高质量数据源收集问题
DS_TO_SELECTION = {
    "MATH": [load_math, None, None],                    # 12K样本
    "OlympicArena": [load_olympic_arena, None, None],  # 3922样本
    "TheoremQA": [load_theoremqa, None, None],         # 720样本
    "NuminaMath": [load_numinamath, None, None],
    # ... 更多数据源
}
```

数据源包括：
- 数学竞赛题（MATH, AIME, Olympiad）
- 科学问题（Physics, Chemistry, Biology）
- 编程题（USACO, LiveCodeBench）
- 推理题（GPQA, TheoremQA）

#### 第二步：生成思维链 (`data/gemini.py`)
```python
def gemini_qa(prompt: str):
    client = genai.Client(api_key="YOUR_API_KEY")
    response = client.models.generate_content(
        model="gemini-2.0-flash-thinking-exp",
        contents=prompt
    )
    thinking = response.candidates[0].content.parts[0].text  # 思维过程
    answer = response.candidates[0].content.parts[1].text    # 最终答案
    return thinking, answer
```

#### 第三步：数据格式化 (`data/tokenization.py`)
```python
def process_cot_example(example: Dict, tokenizer):
    thinking_trajectory = example["thinking_trajectories"]
    question = example["question"]
    answer = example["attempt"]
    
    # 构建训练格式
    text = tokenizer.apply_chat_template([
        {"role": "user", "content": question},
        {
            "role": "assistant", 
            "content": "<|im_start|>think\n" + 
                      "\n".join(thinking_trajectory).strip() + 
                      "\n<|im_start|>answer\n" + 
                      answer.strip()
        }
    ], tokenize=False)
    return dict(text=text)
```

### 2.2 最终数据格式
```
<|im_start|>system
You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
<|im_end|>
<|im_start|>user
How many r in raspberry?
<|im_end|>
<|im_start|>assistant
<|im_start|>think
Let me count the letter 'r' in the word "raspberry".
The word is: r-a-s-p-b-e-r-r-y
Looking at each letter:
- r: this is an 'r' (1st r)
- a: not an 'r'
- s: not an 'r'
- p: not an 'r'
- b: not an 'r'
- e: not an 'r'
- r: this is an 'r' (2nd r)
- r: this is an 'r' (3rd r)
- y: not an 'r'
<|im_start|>answer
There are 3 r's in the word "raspberry".
<|im_end|>
```

---

## 3. 训练机制

### 3.1 SFT训练配置 (`train/sft.py`)

```python
@dataclass
class TrainingConfig:
    model_name: str = "Qwen/Qwen2.5-32B-Instruct"
    block_size: int = 32768  # 最大序列长度
    train_file_path: str = 'simplescaling/s1K_tokenized'
```

### 3.2 损失计算策略

只在assistant的回复部分计算损失：
```python
# 使用特殊的数据整理器
collator = trl.DataCollatorForCompletionOnlyLM(
    instruction_template="<|im_start|>user",
    response_template="<|im_start|>assistant\n",
    tokenizer=tokenizer,
    mlm=False
)
```

这确保模型只学习如何生成思维链和答案，而不是学习用户的问题。

### 3.3 训练命令

```bash
# 基础训练
bash train/sft.sh

# 多节点训练（16个H100 GPU）
bash train/sft_multinode.sh
```

---

## 4. 推理机制

### 4.1 基础推理模式

模型自主决定是否使用思维链：
```python
# 标准推理
prompt = """<|im_start|>system
You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
<|im_end|>
<|im_start|>user
How many r in raspberry
<|im_end|>
<|im_start|>assistant
"""

response = model.generate(prompt, sampling_params)
# 模型可能直接回答，也可能先输出<|im_start|>think进行思考
```

### 4.2 预算强制（Budget Forcing）

强制模型使用思维链，并控制思考长度：

```python
# 步骤1：初始生成
prompt = "<|im_start|>user\n" + question + "<|im_end|>\n<|im_start|>assistant\n"

# 步骤2：强制添加思维链标记
prompt += "<|im_start|>think"

# 步骤3：设置思维链专用的停止标记
stop_token_ids = tok("<|im_start|><|im_end|>")["input_ids"]
sampling_params = SamplingParams(
    max_tokens=MAX_TOKENS_THINKING,  # 限制思维链长度
    stop_token_ids=stop_token_ids,
    temperature=0.0
)

# 步骤4：生成思维过程
thinking_output = model.generate(prompt, sampling_params)

# 步骤5：可选 - 使用"Wait"延长思考
for i in range(NUM_IGNORE):
    prompt += thinking_output[0].outputs[0].text + "Wait"
    thinking_output = model.generate(prompt, sampling_params)

# 步骤6：生成最终答案
prompt += thinking_output[0].outputs[0].text
stop_token_ids = tok("<|im_end|>")["input_ids"]  # 切换回正常停止标记
final_output = model.generate(prompt, sampling_params)
```

### 4.3 高级控制策略

#### Token条件控制
```bash
# 控制思维链使用特定数量的token
PROMPTTOKEN=4096 lm_eval --model vllm \
  --model_args pretrained=simplescaling/token-conditional-control \
  --gen_kwargs "max_gen_toks=32768,max_tokens_thinking=4096"
```

#### 步骤条件控制
```bash
# 控制思维链使用特定数量的推理步骤
PROMPTSTEP=64 lm_eval --model vllm \
  --model_args pretrained=simplescaling/step-conditional-control \
  --gen_kwargs "max_gen_toks=32768,thinking_start=<|im_start|>,thinking_end=<|im_start|>answer"
```

#### 拒绝采样（Rejection Sampling）
```python
# 生成多个思维链，选择最佳答案
sampling_params = SamplingParams(
    max_tokens=32768,
    max_tokens_thinking=8000,
    rejection_sample=True,
    temperature=1.0  # 使用温度采样增加多样性
)
```

---

## 5. Prompt设计

### 5.1 训练时的Prompt模板

```python
QUERY_TEMPLATE_NOANSWER = "{Question}"

# 完整的训练样本
training_text = tokenizer.apply_chat_template([
    {"role": "user", "content": QUERY_TEMPLATE_NOANSWER.format(Question=question)},
    {
        "role": "assistant", 
        "content": "<|im_start|>think\n" + thinking + "\n<|im_start|>answer\n" + answer
    }
], tokenize=False)
```

### 5.2 推理时的Prompt变体

#### 变体1：标准推理
```
<|im_start|>system
You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
<|im_end|>
<|im_start|>user
[用户问题]
<|im_end|>
<|im_start|>assistant
```

#### 变体2：强制思维链
```
[标准prompt] + "<|im_start|>think"
```

#### 变体3：带提示的推理
```
<|im_start|>system
You are a helpful and harmless assistant. You are Qwen developed by Alibaba. 
You should think step-by-step.
<|im_end|>
<|im_start|>user
[用户问题]
<|im_end|>
<|im_start|>assistant
```

---

## 6. 代码示例

### 6.1 使用vLLM进行推理

```python
from vllm import LLM, SamplingParams
from transformers import AutoTokenizer

# 初始化模型
model = LLM(
    "simplescaling/s1.1-32B",
    tensor_parallel_size=2,
)
tokenizer = AutoTokenizer.from_pretrained("simplescaling/s1-32B")

# 基础推理
def basic_inference(question):
    prompt = f"""<|im_start|>system
You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
<|im_end|>
<|im_start|>user
{question}
<|im_end|>
<|im_start|>assistant
"""
    
    sampling_params = SamplingParams(
        max_tokens=32768,
        stop_token_ids=tokenizer("<|im_end|>")["input_ids"],
        temperature=0.0
    )
    
    output = model.generate(prompt, sampling_params)
    return output[0].outputs[0].text

# 预算强制推理
def budget_forcing_inference(question, max_thinking_tokens=32000, num_wait=1):
    # 初始prompt
    prompt = f"""<|im_start|>system
You are Qwen, created by Alibaba Cloud. You are a helpful assistant.
<|im_end|>
<|im_start|>user
{question}
<|im_end|>
<|im_start|>assistant
<|im_start|>think"""
    
    # 生成思维链
    thinking_params = SamplingParams(
        max_tokens=max_thinking_tokens,
        stop_token_ids=tokenizer("<|im_start|><|im_end|>")["input_ids"],
        temperature=0.0
    )
    
    thinking_output = model.generate(prompt, thinking_params)
    prompt += thinking_output[0].outputs[0].text
    
    # 添加Wait延长思考
    for _ in range(num_wait):
        prompt += "Wait"
        thinking_output = model.generate(prompt, thinking_params)
        prompt += thinking_output[0].outputs[0].text
    
    # 生成最终答案
    answer_params = SamplingParams(
        max_tokens=32768,
        stop_token_ids=tokenizer("<|im_end|>")["input_ids"],
        temperature=0.0
    )
    
    final_output = model.generate(prompt, answer_params)
    return prompt + final_output[0].outputs[0].text
```

### 6.2 使用transformers进行推理

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

model_name = "simplescaling/s1.1-32B"
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

def inference_with_transformers(question):
    messages = [
        {"role": "system", "content": "You are a helpful and harmless assistant. You are Qwen developed by Alibaba. You should think step-by-step."},
        {"role": "user", "content": question}
    ]
    
    text = tokenizer.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True
    )
    
    model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
    
    generated_ids = model.generate(
        **model_inputs,
        max_new_tokens=32768
    )
    
    generated_ids = [
        output_ids[len(input_ids):] 
        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
    ]
    
    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return response
```

---

## 7. 关键创新点

### 7.1 数据效率
- 仅使用1000个高质量样本（s1K）就能达到优秀性能
- 通过精心选择的数据源确保覆盖多样化的推理任务

### 7.2 灵活的思维链控制
- **隐式学习**：模型通过训练学会何时需要思考
- **显式控制**：可以在推理时强制触发思维链
- **长度控制**：通过max_tokens_thinking参数精确控制思考长度
- **多种控制策略**：Token控制、步骤控制、类别控制等

### 7.3 测试时扩展（Test-time Scaling）
- **预算强制**：在推理时可以让模型思考更长时间
- **Wait机制**：通过插入"Wait"等词汇延长思考过程
- **拒绝采样**：生成多个答案选择最佳

### 7.4 实现简洁性
- 不需要复杂的强化学习或特殊的训练技巧
- 使用标准的SFT（监督微调）即可
- 特殊标记设计简单但有效

---

## 8. 实践建议

### 8.1 何时使用思维链
- **复杂推理任务**：数学证明、多步骤问题
- **需要展示过程**：教育场景、解释性任务
- **提高准确性**：对于容易出错的任务

### 8.2 参数调优建议
```python
# 简单问题
max_thinking_tokens = 1000-2000

# 中等复杂度
max_thinking_tokens = 4000-8000

# 高难度问题（如AIME竞赛题）
max_thinking_tokens = 16000-32000

# Wait次数建议
num_wait = 1-2  # 通常1-2次就足够
```

### 8.3 性能优化
- 使用vLLM进行高效推理
- 合理设置tensor_parallel_size
- 对于批量推理，使用适当的batch_size

---

## 9. 常见问题

### Q1: 为什么使用`<|im_start|>think`而不是其他标记？
A: 这是基于Qwen模型的特殊标记体系，`<|im_start|>`是该模型的控制标记前缀。

### Q2: 模型总是会输出思维链吗？
A: 不一定。在基础推理模式下，模型会根据问题复杂度自主决定。只有在预算强制模式下才会强制输出。

### Q3: Wait机制的原理是什么？
A: Wait作为一个"忽略词"，让模型在达到token限制时可以继续思考，类似于人类思考时的"嗯..."或"让我再想想..."。

### Q4: 如何评估思维链的质量？
A: 可以通过以下指标：
- 最终答案的准确性
- 思维过程的逻辑性
- 思考步骤的完整性
- 平均思考token数

---

## 10. 总结

s1项目展示了一个优雅而有效的思维链实现方案：
1. **数据高效**：1000个样本达到SOTA性能
2. **控制灵活**：多种方式控制思维链生成
3. **实现简单**：标准SFT训练，无需复杂技巧
4. **效果显著**：在数学推理等任务上达到o1-preview级别

这个项目为大语言模型的推理能力提升提供了一个实用的解决方案，特别适合需要展示推理过程的应用场景。

---

## 参考资源

- **论文**: [s1: Simple test-time scaling](https://arxiv.org/abs/2501.19393)
- **模型**: [HuggingFace - s1.1-32B](https://huggingface.co/simplescaling/s1.1-32B)
- **数据集**: [HuggingFace - s1K-1.1](https://huggingface.co/datasets/simplescaling/s1K-1.1)
- **GitHub**: [simplescaling/s1](https://github.com/simplescaling/s1)

---

*本文档基于s1项目源代码整理，旨在帮助理解思维链的实现机制。*
